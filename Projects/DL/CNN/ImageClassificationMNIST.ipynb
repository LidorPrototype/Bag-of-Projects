{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Website: https://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network, Steps:\n",
    "1. Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
    "2. Normalize the image pixel values (divide by 255)\n",
    "3. One-Hot Encode the categorical column\n",
    "4. Build a model architecture (Sequential) with Dense layers(Fully connected layers)\n",
    "5. Train the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot encoding using tensorflow.keras numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a linear stack of layers with the sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "model.add(Dense(100, input_shape = (784,), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3740 - accuracy: 0.8967 - val_loss: 0.2061 - val_accuracy: 0.9398\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9488 - val_loss: 0.1499 - val_accuracy: 0.9556\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1309 - accuracy: 0.9618 - val_loss: 0.1188 - val_accuracy: 0.9652\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1029 - accuracy: 0.9704 - val_loss: 0.1040 - val_accuracy: 0.9688\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9755 - val_loss: 0.1056 - val_accuracy: 0.9690\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9794 - val_loss: 0.0881 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.0829 - val_accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9850 - val_loss: 0.0814 - val_accuracy: 0.9760\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9877 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9894 - val_loss: 0.0764 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2353c25e4f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model for N epochs\n",
    "N = 10\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = N, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One major advantage of using ConvNets over NNs is that you do not need to flatten the input images to 1D as they are capable of working with image data in 2D. This helps in retaining the \"spatial\" properties of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot encoding using tensorflow.keras numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a linear stack of layers with the sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer\n",
    "model.add(Conv2D(25, kernel_size = (3, 3), strides = (1, 1), padding = 'valid', activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size = (1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten output of convolutional layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layer\n",
    "model.add(Dense(100, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 25)        250       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 26, 26, 25)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16900)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               1690100   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1691360 (6.45 MB)\n",
      "Trainable params: 1691360 (6.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 22s 45ms/step - loss: 0.2081 - accuracy: 0.9382 - val_loss: 0.0876 - val_accuracy: 0.9727\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.0593 - val_accuracy: 0.9794\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.0557 - val_accuracy: 0.9816\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0485 - val_accuracy: 0.9834\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0514 - val_accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0539 - val_accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0591 - val_accuracy: 0.9836\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0565 - val_accuracy: 0.9848\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0589 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23539ea3820>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = 10\n",
    "model.fit(X_train, Y_train, batch_size = 128, epochs = E, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
