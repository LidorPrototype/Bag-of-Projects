<div dir="rtl">
הסבר כללי על מודלי ערבוב גאוסיים:

דבר ראשון המודל מניח שיש התפלגויות גאוסיות במידע, והמודל הזה משומש לרוב כאשר המידע מגיע ממספר מקורות שונים,
המודל משתמש באלגוריתם שנקרא Expectation-Maximization (EM) בכול צעד E ההסתברות של כול מקור מחושב מחדש (ככה מגלים את החשיבות שלהם) ובכול צעד M המודל מעדכן את כול הפרמטרים על מנת למקסם את ההסתברות של החשיבויות הללו, התהליך של EM ממשיך איטרטיבית עד שמגיעים לתוצאה מספיקה או תנאי עצירה כולשהו
המודלים מאפשרים חפיפה של קבוצות הנתונים, יכול לקרות שיהיה חתיכת מידע שיש לה קשר גם לקבוצה א' וגם לקבוצה ב' לדוגמה (נגיד אם מסדרים בועות לפי צורה יכולה להיות בועה עם צורה שדומה לכמה קבוצות של צורות)
